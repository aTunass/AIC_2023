{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8fO1R5Q_PH7",
        "outputId": "e36d79ec-f005-4810-ade2-6d5140e6e5da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BLIP/BLIP\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/BLIP/BLIP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93fDsKapAsw3",
        "outputId": "e5728fe5-d67b-44f2-f84e-c2eea5c1f344"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp310-cp310-linux_x86_64.whl size=552447 sha256=8e8752baa6ac79c37c2fb7a707408b0341f22bb77a3be865926f58248d9c9525\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/8a/da/f714bcf46c5efdcfcac0559e63370c21abe961c48e3992465a\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "import json\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "raUyFF1DASt2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyAnnoy:\n",
        "  def __init__(self, model, image_size, json_path, metric, ntrees, feature_shape):\n",
        "    self.model = model\n",
        "    self.image_size = image_size\n",
        "    self.dict_id2image_path = self.load_json(json_path)\n",
        "    self.metric = metric\n",
        "    self.ntrees = ntrees\n",
        "    self.feature_shape = feature_shape\n",
        "\n",
        "  #parse json to dictionary id : image_path\n",
        "  def load_json(self, json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "      js = json.loads(f.read())\n",
        "\n",
        "    return {int(id): image_path for image_path, id in js.items()}\n",
        "\n",
        "  def buildAnnoyIndex(self, save_path):\n",
        "    annoy_index = AnnoyIndex(self.feature_shape, self.metric)\n",
        "\n",
        "    for i in len(self.dict_id2image_path):\n",
        "      image_path = self.dict_id2image_path[i]\n",
        "      image_input = self.load_image(image_path, self.image_size)\n",
        "\n",
        "      output_feature = self.model.image_feature[0]\n",
        "\n",
        "      annoy_index.add_item(i, output_feature)\n",
        "\n",
        "    annoy_index.build(self.ntrees)\n",
        "    annoy_index.save(save_path)\n",
        "\n",
        "  def load_annoy(self, annoy_path):\n",
        "    annoy_index = AnnoyIndex(self.feature_shape, self.metric)\n",
        "    annoy_index.load(annoy_path)\n",
        "    return annoy_index\n",
        "\n",
        "  def annoy_image_search(self, annoy_index, image_path, topk):\n",
        "    image_input = self.load_image(image_path, self.image_size)\n",
        "\n",
        "    output_feature = self.model.image_feature(image_input)[0]\n",
        "    index_image = annoy_index.get_nns_by_vector(output_feature, topk)\n",
        "\n",
        "    return index_image\n",
        "\n",
        "  def annoy_text_image_search(self, annoy_index, text, topk):\n",
        "    output_feature = self.model.text_feature(text)[0]\n",
        "    index_image = annoy_index.get_nns_by_vector(output_feature, topk)\n",
        "\n",
        "    return index_image\n",
        "\n",
        "  @staticmethod\n",
        "  def load_image(image_path, image_size):\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size), interpolation=InterpolationMode.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        ""
      ],
      "metadata": {
        "id": "TOn8GmxY_R85"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y6gwknsC_R_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_BYjYpDB_SB4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}